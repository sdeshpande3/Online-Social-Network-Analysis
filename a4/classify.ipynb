{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "import pickle\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tweets(name):\n",
    "    \"\"\"\n",
    "    Load stored tweets.\n",
    "    List of strings, one per tweet.\n",
    "    \"\"\"\n",
    "    with open(name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_afin():\n",
    "\n",
    "    url = urlopen('http://www2.compute.dtu.dk/~faan/data/AFINN.zip')\n",
    "    file = ZipFile(BytesIO(url.read()))\n",
    "    afin_f = file.open('AFINN/AFINN-111.txt')\n",
    "    return afin_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file):\n",
    "\n",
    "    afinn = {}\n",
    "    for l in file:\n",
    "        line = l.strip().split()\n",
    "        if len(line) == 2:\n",
    "            afinn[line[0].decode(\"utf-8\")] = int(line[1])\n",
    "    return afinn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet_sentiment(terms, afinn, verbose=False):\n",
    "\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for t in terms:\n",
    "        if t in afinn:\n",
    "            if verbose:\n",
    "                print('\\t%s=%d' % (t, afinn[t]))\n",
    "            if afinn[t] > 0:\n",
    "                pos += afinn[t]\n",
    "            else:\n",
    "                neg += -1 * afinn[t]\n",
    "    return pos, neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc, keep_internal_punct = False):\n",
    "    convert = doc.lower();\n",
    "    if keep_internal_punct == False:\n",
    "        return np.array(re.findall(\"[\\w_]+\", convert))\n",
    "    else:\n",
    "        return np.array(re.findall('[\\w_][^\\s]*[\\w_]|[\\w_]', convert))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_features(tokens, feats):\n",
    "    cnt = Counter(tokens)\n",
    "    for i in cnt:\n",
    "        feats[\"token=\"+i] = cnt[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_pair_features(tokens, feats, k=3):\n",
    "    windows = []\n",
    "    def window_creator(list,degree):\n",
    "        for ws in range(len(tokens) - degree + 1):\n",
    "            yield [list[ws+l] for l in range(degree)]\n",
    "\n",
    "    window_generator = window_creator(tokens,k)\n",
    "\n",
    "    for window in window_generator:\n",
    "        subseq = [c[0]+\"__\"+c[1] for c in combinations(window,2)]\n",
    "        for sub in subseq:\n",
    "            if \"token_pair=\"+sub not in feats:\n",
    "                feats[\"token_pair=\"+sub] = 1\n",
    "            elif \"token_pair=\"+sub in feats:\n",
    "                feats[\"token_pair=\"+sub] = feats[\"token_pair=\"+sub] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lexicon_features(tokens, feats):\n",
    "    feats['pos_words'] = 0\n",
    "    feats['neg_words'] = 0\n",
    "\n",
    "    for token in tokens :\n",
    "        if(token.lower() in pos_words):\n",
    "            feats['pos_words'] += 1\n",
    "        elif(token.lower() in neg_words):\n",
    "            feats['neg_words'] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def featurize(tokens, feature_fns):\n",
    "    feats = {}\n",
    "    for features in feature_fns:\n",
    "        features(tokens,feats)\n",
    "\n",
    "    result = [(x, y) for x, y in feats.items()]\n",
    "\n",
    "    return sorted(result,key=lambda x:x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment(tweets,tokens,afin):\n",
    "\n",
    "    posv = []\n",
    "    negv = []\n",
    "    combo = []\n",
    "    for tk, tw in zip(tokens, tweets):\n",
    "        pos, neg = tweet_sentiment(tk, afin)\n",
    "        if neg == pos:\n",
    "            combo.append((tw['text'], pos, neg))\n",
    "        elif neg > pos:\n",
    "            negv.append((tw['text'], pos, neg))\n",
    "        elif pos > neg:\n",
    "            posv.append((tw['text'], pos, neg))\n",
    "    return posv, negv, combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_obj(obj, name):\n",
    "    with open(name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "got tweets!\n",
      "afin data downloaded and read!\n",
      "There are 138 positive tweets, 81 negative tweets and 146 neutral tweets.\n",
      "classify saved!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "\n",
    "    tweets = get_tweets('tweets')\n",
    "    print(\"got tweets!\")\n",
    "    afin = download_afin()\n",
    "    read = read_data(afin)\n",
    "    print(\"afin data downloaded and read!\")\n",
    "    tokens = [tokenize(t['text']) for t in tweets]\n",
    "    positives, negatives, combined =sentiment(tweets,tokens,read)\n",
    "    print(\"There are %d positive tweets, %d negative tweets and %d neutral tweets.\" \n",
    "          % (len(positives), len(negatives),len(combined)))\n",
    "    classify = (positives,negatives,combined)\n",
    "    save_obj(classify, 'classify')\n",
    "    print(\"classify saved!\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
